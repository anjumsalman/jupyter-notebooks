{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cc1555-20dc-4a01-8548-8efa0a1f5741",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Controls rate of traffic from client to server. Rate is often set as in terms of $n$ requests per second. Any request going beyond the set limit is blocked. There are multiple advantages of using rate limiter:\n",
    "- prevents system from being overwhelmed in case of excess traffic. Denial of Service attacks involve sending large number of request with the aim of resource starvation.\n",
    "- prevents excess charge being incurred in case we are using per request chargeable third party API.\n",
    "\n",
    "Rate limiter can be applied both at client and server side - however client side rate limiting cannot be relied upon since it is easy to modify client.\n",
    "\n",
    "### Granularity\n",
    "Usually, the rate limiter in production is very granular:\n",
    "- rate limiter is defined in terms of $n$ number of request in unit time **per user**\n",
    "- it can be even more specific so as to apply different rates for different APIs. For example, less critical APIs such as analytics can have a lower limit set, whereas more critical API such as transaction ones have higher limit set.\n",
    "\n",
    "<img src=\"images/rate_limiter.png\" />\n",
    "\n",
    "A desirable rate limiter has the following properties:\n",
    "- is efficient: has minimal effect on response time and uses least amount of memory possible\n",
    "- rate limiter can be shared across multiple servers or processes - works well in a distributed system\n",
    "- throttled users are clearly notified \n",
    "- failure with rate limiter should not effect the entire system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99adc29-41c2-4ed0-86f6-3abb93e44179",
   "metadata": {},
   "source": [
    "## Strategies\n",
    "There are multiple different ways to implement a rate limiter as discussed below:\n",
    "\n",
    "### Token Bucket Algorithm\n",
    "<img src=\"images/token_bucket.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bae6b1-7b2f-4385-83de-a283c6c69f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// This implementation is not thread safe\n",
    "class TokenBucketLimiter {\n",
    "    final int RATE;  // Unit is seconds\n",
    "    final int MAX_BUCKET_SIZE;\n",
    "    \n",
    "    TokenBucketLimiter(int rate, int maxBucketSize) {\n",
    "        this.RATE = rate;\n",
    "        this.MAX_BUCKET_SIZE = maxBucketSize;\n",
    "    }\n",
    "    \n",
    "    long lastTime = System.currentTimeMillis();\n",
    "    int currentBucketSize = 0;\n",
    "    \n",
    "    handle(Request request, Consumer<Request> successHandler, Consumer<Request> failureHandler) {\n",
    "        long currentTime = System.currentTimeMillis();\n",
    "        long elapsedTime = (lastTime - currentTime) / 1000; // in seconds\n",
    "        lastTime = currentTime;\n",
    "        \n",
    "        // Update the bucket occupancy\n",
    "        currentBucketSize = currentBucketSize + (RATE * elapsed);\n",
    "        // Overflow? Rest the bucket in case of overflow\n",
    "        if(currentBucketSize > MAX_BUCKET_SIZE) {\n",
    "            currentBucketSize = MAX_BUCKET_SIZE;\n",
    "        }\n",
    "        \n",
    "        if(currentBucketSize < 1) {\n",
    "            failureHandler.accept(request);\n",
    "        } else {\n",
    "            currentBucketSize--; // consume 1 token\n",
    "            successHandler.accept(request);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3694cdc-345b-421c-9c86-60073ce19f41",
   "metadata": {},
   "source": [
    "To translate this process to a distrubuted world, we'll need something like a global store like Redis. The buckets are then stored in Redis. In case of Redis, the script above needs to run atomically, something that Redis transactions can provide. Both `currentBucketSize` and `lasTime` will be stored as two set of keys per user.\n",
    "\n",
    "In order to support burst mode (wherein we allow client to go above the limit for a short period of time), we can initialize bucket with larger number of tokens than the capacity of the bucket. This means that when the bucket is full, a user can go beyond the specified rate for a brief moment of time.\n",
    "\n",
    "References: [KrakenD Documentation](https://www.krakend.io/docs/throttling/token-bucket/), [Wikipedia](https://en.wikipedia.org/wiki/Token_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb3292c-fc2c-43f7-8b6c-0ef297847c30",
   "metadata": {},
   "source": [
    "### Fixed Window Counter\n",
    "In this strategy, we divide timeline into fixed width windows, for example 1sec windows. Each incoming request increases the counter of that window by one. If the counter has already reached threshold, any incoming request in that window is rejected until new window starts.\n",
    "\n",
    "<img src=\"images/fixed_window.png\" />\n",
    "\n",
    "Fixed window however may not always be accurate, allowing as much as twice the number of requests in a given rolling window:\n",
    "\n",
    "<img src=\"images/fixed_window_problem.png\" />\n",
    "\n",
    "As we can see in the above figure, we have twice the max number of allowed requests in the window `1:00:0:500` and `1:00:01:500` without triggering the rate limiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459691d-87d1-44a8-9d11-383819acbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedWindowLimiter {\n",
    "    final int RATE // Unit is seconds\n",
    "    \n",
    "    // In this simplistic implementation, stale entries are not being removed\n",
    "    Map<Long, AtomicInteger> requestWindows = new ConcurrentHashMap<>();\n",
    "    \n",
    "    handle(Request request, Consumer<Request> successHandler, Consumer<Request> failureHandler) {\n",
    "        long currentTime = System.currentTimeMillis();\n",
    "        currentTime = currentTime / 1000 * 1000;\n",
    "        \n",
    "        requestWindows.putIfAbsent(currentTime, new AtomicInteger(0));\n",
    "        boolean allowed = requestWindows.get(currentTime).incrementAndGet() <= RATE;\n",
    "\n",
    "        if(!allowed) {\n",
    "            failureHandler.accept(request);\n",
    "        } else {\n",
    "            successHandler.accept(request);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85b820-560b-4be5-b396-65532eaf4946",
   "metadata": {},
   "source": [
    "### Sliding Window Log\n",
    "In this strategy, we log timestamp for each request. For every new request, we look back by the window time amount and count the number of request made in the window:\n",
    "\n",
    "<img src=\"images/sliding_window_log.png\" width=\"900\" height=\"auto\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62259d1a-dbda-4623-a57d-f9c2713aae63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "// Not thread safe\n",
    "class SlidingWindowLogLimiter {\n",
    "    final int RATE // Unit is seconds\n",
    "    \n",
    "    Queue<Long> requestLog = new LinkedList<>();\n",
    "    \n",
    "    handle(Request request, Consumer<Request> successHandler, Consumer<Request> failureHandler) {\n",
    "        long currentTime = System.currentTimeMillis();\n",
    "        long window = currentTime - 1000; // 1 sec window\n",
    "        \n",
    "        // Remove all logs outside of the window\n",
    "        while(!requestLog.isEmpty() && requestLog.element() <= window) {\n",
    "            requestLog.poll();\n",
    "        }\n",
    "        \n",
    "        boolean allowed = requestLog.size() <= RATE;\n",
    "\n",
    "        if(!allowed) {\n",
    "            failureHandler.accept(request);\n",
    "        } else {\n",
    "            requestLog.add(currentTime);\n",
    "            successHandler.accept(request);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be935b-22db-49aa-b4fb-59d8e0b1d0cd",
   "metadata": {},
   "source": [
    "Sliding window log is very accurate, however it takes up extra memory in form of the `requestLog` as shown in the code example above.\n",
    "\n",
    "### Sliding Window Counter\n",
    "Combines sliding window log and fixed window counter approaches. One assumption we make is that the requests made in each window is distributed equally through the duration of the window. Of course this assumption makes this strategy less accurate than sliding window log, however that balances over time. Number of requests made in a sliding window is calculated as: `req in current window + req in prev window * overlap percentage`.\n",
    "\n",
    "<img src=\"images/sliding_window_counter.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9793f59-33b0-490c-9eb1-06f3b5dfaabb",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "<img src=\"images/rate_limiter_arch.png\" />\n",
    "\n",
    "1. Request arrives from a client. The rate limiter middleware would have to now decide whether to allow or reject the request\n",
    "2. Rate limits are usually defined as configurations. In this setup the rate limiter middleware fetches and saves the rule. Any updates in rule is forwarded over to the rate limiter.\n",
    "3. The rate limiter saves its data on a cache preferably with transactions support, for example Redis. This cache is where buckets in case of token bucket algorithm would be stored.\n",
    "4. Requests below the limit are reach application servers. In this case we have stateless APIs.\n",
    "5. Requests above the limit are rejected with a status 429 response. Additional information such as wait time or currently set limit can also be in the response as headers.\n",
    "6. We can also choose to save the rejected requests in a message log and retry processing them when we know the load on system is low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062232a8-28a5-4009-b90d-1cbf80e99154",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "21.0.2+13-58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
