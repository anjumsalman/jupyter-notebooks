{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96bd1d04-6335-474c-aa4a-4990fa9acb21",
   "metadata": {},
   "source": [
    "## Overview\n",
    "A producer writes messages to a Kafka topic. Many different types of data can be written with varying appetite for message duplication and failure. Producer is composed of the many components and follows the below message publishing flow:  \n",
    "<img src=\"images/producer_flow.png\" />\n",
    "\n",
    "A message in Kafka is represented using a `ProducerMessage` which is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f535a-73ea-4489-a3d8-efb046934ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "public class ProducerRecord<K, V> {\n",
    "    private final String topic;  // required\n",
    "    private final Integer partition;\n",
    "    private final Headers headers;  // can be used to add context like trace id\n",
    "    private final K key;\n",
    "    private final V value;  // required\n",
    "    private final Long timestamp;  // System.currentTimeMillis() if not specified\n",
    "\n",
    "    // ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227841e-df41-4d3a-a8b4-92ea8a42c8f0",
   "metadata": {},
   "source": [
    "The `key` and `value` components are serialized and sent over network. If the `partition` is not specified, the partitioner will select a partition using the `key`.\n",
    "\n",
    "Once the message is successfully written, we get back a `RecordMetadata` containing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e264dbc-7455-409b-abda-65dc7594ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "public final class RecordMetadata {\n",
    "    private final long offset;\n",
    "    private final long timestamp;  // same as in ProducerRecord\n",
    "\n",
    "    private final TopicPartition topicPartition;\n",
    "    // ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0411b5-8e31-4710-bd12-ed8b7c67daab",
   "metadata": {},
   "source": [
    "### Serializer\n",
    "Serializer is a piece of code on the Producer side responsible for converting Java objects (or any other language-specific data structure) into a byte array (`byte[]`). This conversion is essential because Kafka is a byte-oriented system; it stores and transmits all data - `key` and `value` as raw arrays of bytes.\n",
    "\n",
    "Kafka client provides multiple different serializers all inheriting from `Serializer<T>` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb90258-2e80-4ca7-9120-aa0eaa744a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "public interface Serializer<T> extends Closeable {\n",
    "    byte[] serialize(String topic, T data);\n",
    "    // ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029e758-b75d-4e39-800e-43bdd33b4b67",
   "metadata": {},
   "source": [
    "Some implementations are:\n",
    "- `StringSerializer`: used to serialize string keys and values. It converts a string to `byte[]` using the specified encoding.\n",
    "- `IntegerSerializer`: used to serialize integer keys and values.\n",
    "- `JsonPOJOSerializer`: used to serialize Java POJO keys and values as JSON `byte[]`. It uses library like Jackson\n",
    "\n",
    "### Partitioner\n",
    "Partitioner is responsible for determining which partition a specific `ProducerRecord` should be sent to within a topic. Partitioners help distribute message across partitions acting as load balancer. It also ensures message ordering if required (by sending similar messages to same partition).\n",
    "\n",
    "Partitioner works in the following manner:\n",
    "1. If the `ProducerRecord` explicitly specifies a `partition` number, the Partitioner simply uses this value.\n",
    "2. If the `partition` is not specified, but a `key` is present in the `ProducerRecord`, the Partitioner uses a hashing algorithm on the key.\n",
    "3. If both the `partition` and the `key` are `null`, the Partitioner's goal shifts to simply distributing the load as evenly and efficiently as possible. A round-robin algorithm will be used to balance the messages among the partitions.\n",
    "\n",
    "Thus, it means that **it is the producer's responsibility to decide which partition to send data to**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd59b71-6516-4376-afc3-1f9c96aaa3f3",
   "metadata": {},
   "source": [
    "## Constructing Producer\n",
    "Producer object facilitates thread safe publishing of messages to Kafka. To instantiate a producer object, we need the following mandatory properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886c801-2344-45c8-a956-6b34bbb081e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "private Properties kafkaProps = new Properties();\n",
    "kafkaProps.put(\"bootstrap.servers\", \"broker1:9092,broker2:9092\");  // list of host:port pairs of brokers\n",
    "kafkaProps.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n",
    "kafkaProps.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n",
    "\n",
    "KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b23833-bc52-4b4c-86c9-2788381bef55",
   "metadata": {},
   "source": [
    "Full list of producer configuration properties [here](https://kafka.apache.org/documentation.html#producerconfigs). However some important ones are listed below:\n",
    "\n",
    "| Property                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
    "|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| acks                      | `acks=0`, producer will not wait for a reply from the broker before assuming the message was sent successfully. High throughput, but producer will not know about any failures. `acks=1`, producer will receive a success response from the broker the moment the leader replica received the message. `acks=all`, producer will receive a success response from the broker once all in-sync replicas received the message. High latency. |\n",
    "| buffer.memory             | sets the amount of memory the producer will use to buffer messages waiting to be sent to brokers. If messages are sent by the application faster than they can be delivered to the server, the producer may run out of space and additional `send()` calls will either block or throw an exception, based on the `block.on.buffer.full` prop.                                                                                         |\n",
    "| compression.type          | can be set to snappy, gzip, or lz4.                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
    "| retries                   | how many times the producer will retry sending the message before giving up and notifying the client of an issue. Producer will wait `retry.backoff.ms` amount of time before retrying.                                                                                                                                                                                                                                             |\n",
    "| client.id                 | used by broker to identify client                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
    "| timeout.ms                | controls the time the broker will wait for in-sync replicas to acknowledge the message.                                                                                                                                                                                                                                                                                                                                             |\n",
    "| metadata.fetch.timeout.ms | how long the producer will wait for a reply from the server when sending data.                                                                                                                                                                                                                                                                                                                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0831771-0c74-42d7-98d4-8b21088f514e",
   "metadata": {},
   "source": [
    "## Sending Message\n",
    "There are multiple ways to send messages.\n",
    "\n",
    "**Fire and forget:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116796b5-f9c8-4a25-8c43-0aba3a535931",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProducerRecord<String, String> record = \n",
    "    new ProducerRecord<>(\"CustomerCountry\", \"Precision Products\", \"France\");\n",
    "    // <Topic>,<Key>,<Value>\n",
    "\n",
    "try {\n",
    "    producer.send(record);  // Send returns Future<RecordMetadata>\n",
    "} catch(Exception e) {\n",
    "    logger.error(e);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b91757-6a8e-4692-b92b-b6460aca7f1f",
   "metadata": {},
   "source": [
    "The `send()` method can throw an exception synchronously if the error is detected on the client side before the data is even placed on the network. Example:\n",
    "- Serialization Error: the key or value cannot be converted into bytes using the given serializer. Throws `SerializationException`.\n",
    "- Buffer Exhaustion: the producer's internal buffer is full, and the `max.block.ms` timeout has been reached while waiting for space. Throws `BufferExhaustedException`.\n",
    "- Invalid Topic/Partition: the topic name is invalid, or the partition specified is out of range.\n",
    "- Thread interruption: the producer thread was interrupted\n",
    "\n",
    "If the message is successfully placed in the producer's internal buffer and sent over the network, the `producer.send(record)` call will succeed and return immediately, even if the broker later fails to write the message. Using this pattern one cannot be certain that the message was written to the topic.\n",
    "\n",
    "**Synchronous Send:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db03bf0-948f-4bab-95cc-5fab1a3f8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "try {\n",
    "    producer.send(record).get();\n",
    "} catch(Exception e) {\n",
    "    logger.error(e);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b8661-b509-41bb-9383-472e47312d0c",
   "metadata": {},
   "source": [
    "Using this pattern we be sure that the message was written. Call to `get()` will throw `ExecutionException`.\n",
    "\n",
    "What if `ack` is set to 0? It is equivalent to fire and forget mode. Note that Kafka will not allow consumers to read records until they are written to\n",
    "all in sync replicas. So does setting `ack=0` make any difference in the end to end flow?\n",
    "\n",
    "Some errors are retriable, whereas others aren't. Kafka producer automatically retries in case of retriable exceptions. Examples of retriable exception would be connection error or a \"no leader\" error. Non retriable error would be something like message size being too large.\n",
    "\n",
    "**Asynchronous Send:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8579b-70ba-4e1d-8a54-a32c240890dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(record, (m, e) -> {\n",
    "    if(e != null){\n",
    "        logger.error(e);\n",
    "    }\n",
    "});\n",
    "\n",
    "// The second argument is a org.apache.kafka.clients.producer.Callback interface object\n",
    "// which has one method public void onCompletion(RecordMetadata recordMetadata, Exception e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2641120-dfa1-4707-94af-86ffbee2c939",
   "metadata": {},
   "source": [
    "The callbacks execute in the producerâ€™s main thread. This ensures that when we send two messages to the same partition one after another, their callbacks will be executed in the same order that we sent them.\n",
    "\n",
    "The Kafka producer is designed to be highly efficient by always sending data directly to the *leader broker* for the specific partition it wants to write to. The producer client finds the correct leader broker through a process of metadata discovery and caching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cb1cb6-969a-4154-99d8-8d2047a8580f",
   "metadata": {},
   "source": [
    "## Batching\n",
    "Kafka producer batches messages being sent to improve throughput. Instead of sending every individual record immediately in its own network request, the producer accumulates multiple records into a single logical unit called a batch before transmitting them to the Kafka broker.\n",
    "\n",
    "This beings the following improvement:\n",
    "- fewer network calls\n",
    "- fewer disk writes made by the broker\n",
    "- compression works better\n",
    "\n",
    "Internally, when `send` method is called, the `ProducerRecord` is first kept in memory buffer. Separate buffers are maintained for every unique topic-partition combination. The batch is marked as closed and subsequently sent to broker when:\n",
    "- the buffer size matches `batch.size` which is 16KB by default\n",
    "  <div style=\"display: inline-block\">\n",
    "      \n",
    "  | Buffer Queue | Topic\t |Partition ID   | batch.size Limit|  \n",
    "  ---------------|-----------|---------------|-----------------|\n",
    "  | Buffer A\t |UserEvents | 0\t         | 16 KB           | \n",
    "  | Buffer B\t |UserEvents | 1\t         | 16 KB           | \n",
    "  | Buffer C\t |AuditLogs  | 0\t         | 16 KB           | \n",
    "  | Buffer D\t |AuditLogs  | 2\t         | 16 KB           | \n",
    "  \n",
    "- when producer has waited for `linger.ms` (5ms by default) even if the buffer is not full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d148ff2-9dd3-40af-becf-9b0be7c202a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "21.0.2+13-58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
